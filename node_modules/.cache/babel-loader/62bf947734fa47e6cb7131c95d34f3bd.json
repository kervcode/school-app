{"ast":null,"code":"'use strict';\n\nvar assign = require('../constant/assign.js');\n\nvar chunkedSplice = require('./chunked-splice.js');\n\nvar chunkedPush = require('./chunked-push.js');\n\nvar miniflat = require('./miniflat.js');\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js');\n\nvar shallow = require('./shallow.js');\n\nvar resolveAll = require('./resolve-all.js');\n\nvar serializeChunks = require('./serialize-chunks.js');\n\nvar sliceChunks = require('./slice-chunks.js'); // Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesn’t receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\n\n\nfunction createTokenizer(parser, initialize, from) {\n  var point = from ? shallow(from) : {\n    line: 1,\n    column: 1,\n    offset: 0\n  };\n  var columnStart = {};\n  var resolveAllConstructs = [];\n  var chunks = [];\n  var stack = [];\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    }),\n    lazy: constructFactory(onsuccessfulcheck, {\n      lazy: true\n    }) // State and tools for resolving and serializing.\n\n  };\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write // The state function.\n\n  };\n  var state = initialize.tokenize.call(context, effects); // Track which character we expect to be consumed, to catch bugs.\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  } // Store where we are in the input stream.\n\n\n  point._index = 0;\n  point._bufferIndex = -1;\n  return context;\n\n  function write(slice) {\n    chunks = chunkedPush(chunks, slice);\n    main(); // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n\n    addResult(initialize, 0); // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  } //\n  // Tools.\n  //\n\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token));\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  function now() {\n    return shallow(point);\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  } //\n  // State management.\n  //\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n\n\n  function main() {\n    var chunkIndex;\n    var chunk;\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index]; // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  } // Deal with one code.\n\n\n  function go(code) {\n    state = state(code);\n  } // Move a character forward.\n\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    } // Not in a string chunk.\n\n\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++; // At end of string chunk.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    } // Expose the previous character.\n\n\n    context.previous = code; // Mark as consumed.\n  } // Start a token.\n\n\n  function enter(type, fields) {\n    var token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  } // Stop a token.\n\n\n  function exit(type) {\n    var token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  } // Use results.\n\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  } // Discard results.\n\n\n  function onsuccessfulcheck(construct, info) {\n    info.restore();\n  } // Factory to attempt/check/interrupt.\n\n\n  function constructFactory(onreturn, fields) {\n    return hook; // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs;\n      var constructIndex;\n      var currentConstruct;\n      var info;\n      return constructs.tokenize || 'length' in constructs ? handleListOfConstructs(miniflat(constructs)) : handleMapOfConstructs;\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(constructs.null ?\n          /* c8 ignore next */\n          miniflat(constructs[code]).concat(miniflat(constructs.null)) : constructs[code])(code);\n        }\n\n        return bogusState(code);\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        return handleConstruct(list[constructIndex]);\n      }\n\n      function handleConstruct(construct) {\n        return start;\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          if (construct.name && context.parser.constructs.disable.null.indexOf(construct.name) > -1) {\n            return nok();\n          }\n\n          return construct.tokenize.call(fields ? assign({}, context, fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      function ok(code) {\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      function nok(code) {\n        info.restore();\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n\n        return bogusState;\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct);\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  function store() {\n    var startPoint = now();\n    var startPrevious = context.previous;\n    var startCurrentConstruct = context.currentConstruct;\n    var startEventsIndex = context.events.length;\n    var startStack = Array.from(stack);\n    return {\n      restore: restore,\n      from: startEventsIndex\n    };\n\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\nmodule.exports = createTokenizer;","map":null,"metadata":{},"sourceType":"script"}